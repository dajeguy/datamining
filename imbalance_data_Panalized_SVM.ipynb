{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae17af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import imblearn\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Path of the file to read\n",
    "traingData_file_path = 'dm_data/training.csv'\n",
    "testingData_file_path = 'dm_data/testing.csv'\n",
    "data = pd.read_csv(traingData_file_path)\n",
    "testing_data = pd.read_csv(testingData_file_path)\n",
    "\n",
    "y = data.Attrition\n",
    "X = data.drop(['Attrition'], axis=1)\n",
    "\n",
    "# 將原資料分割成驗證集與訓練集\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1177577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin values:\n",
      " 786    Yes\n",
      "422     No\n",
      "890     No\n",
      "320     No\n",
      "280     No\n",
      "Name: Attrition, dtype: object\n",
      "predicted values: [1 1 1 1 1]\n",
      "accuracy score: 0.1864406779661017\n",
      "accuracy score: 0.1864406779661017\n",
      "precise score: 0.17586206896551723\n",
      "recall score: 0.9807692307692307\n",
      "f1 score: 0.2982456140350877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 先將原資料 copy 出來避免後面轉換欄位型態時去更動到原資料\n",
    "\n",
    "label_y_train = train_y.copy()\n",
    "label_y_test = test_y.copy()\n",
    "\n",
    "label_x_train = train_X.copy()\n",
    "label_x_test = test_X.copy()\n",
    "\n",
    "# 轉換要被預測的 class 為 numerical  \n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder1.fit(train_y)\n",
    "label_y_train = label_encoder1.transform(train_y)\n",
    "label_y_test = label_encoder1.fit_transform(np.ravel(test_y))\n",
    "\n",
    "# 轉換 features, 使用 label encoder 將 Categorical 資料轉成 numerical 資料\n",
    "label_x_train = train_X.apply(LabelEncoder().fit_transform)\n",
    "label_x_test = test_X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "# 指定分類模型為 Support vector machine , 搭配 weight 設定為 balanced 來懲罰預測錯誤\n",
    "prediction_model = SVC(class_weight='balanced', probability=True ) #AdaBoostClassifier(random_state=1, n_estimators=70,learning_rate=0.3) # GaussianNB()  KNeighborsClassifier() #AdaBoostClassifier(random_state=1, n_estimators=70,learning_rate=0.3)  #RandomForestClassifier(random_state = 1, max_depth = 18,n_estimators = 500, min_samples_split = 2, min_samples_leaf = 1) #XGBClassifier() #SGDClassifier(loss=\"log\",penalty=\"l2\", max_iter=400) #tree.DecisionTreeClassifier(max_depth=40, random_state=0) #RandomForestClassifier(max_depth=20, random_state=0) #tree.DecisionTreeClassifier()\n",
    "prediction_model.fit(label_x_train, label_y_train)\n",
    "\n",
    "\n",
    "pred = prediction_model.predict(label_x_test)\n",
    "\n",
    "print(\"origin values:\\n\", test_y[0:5])\n",
    "print(\"predicted values:\", pred[0:5])\n",
    "\n",
    "# 將驗證集與預測結果相比較,得出模型的好壞\n",
    "\n",
    "# accuracy\n",
    "#print(label_y_test)\n",
    "#print(pred)\n",
    "print(\"accuracy score:\", accuracy_score(label_y_test, pred))\n",
    "\n",
    "# precise\n",
    "\n",
    "#print(\"precise score:\",precision_score(label_y_test, pred))\n",
    "\n",
    "# recall\n",
    "\n",
    "#print(\"recall score:\", recall_score(label_y_test, pred))\n",
    "\n",
    "# f1 score\n",
    "\n",
    "#print(\"f1 score:\",f1_score(label_y_test, pred))\n",
    "\n",
    "\n",
    "#print(\"\\nmake predictions for new data:\")\n",
    "\n",
    "testing_y = testing_data.Attrition\n",
    "label_testing_y = testing_y.copy()\n",
    "label_testing_y = LabelEncoder().fit_transform(np.ravel(testing_y))\n",
    "\n",
    "\n",
    "# 因為測試資料也會有 Categorical 資料型態出現, 所以也要做轉換\n",
    "\n",
    "# 去掉d class 欄位\n",
    "label_prediction_data = testing_data.drop(['Attrition'], axis=1).copy()\n",
    "\n",
    "# 轉換 features, 使用 label encoder 將 Categorical 資料轉成 numerical 資料\n",
    "label_prediction_data = testing_data.drop(['Attrition'], axis=1).apply(LabelEncoder().fit_transform)\n",
    "\n",
    "result = prediction_model.predict(label_prediction_data)\n",
    "\n",
    "# accuracy\n",
    "\n",
    "print(\"accuracy score:\", accuracy_score(label_y_test, pred))\n",
    "\n",
    "# precise\n",
    "\n",
    "print(\"precise score:\",precision_score(label_y_test, pred))\n",
    "\n",
    "# recall\n",
    "\n",
    "print(\"recall score:\", recall_score(label_y_test, pred))\n",
    "\n",
    "# f1 score\n",
    "\n",
    "print(\"f1 score:\",f1_score(label_y_test, pred))\n",
    "\n",
    "#result\n",
    "#transformed = []\n",
    "#for i in result:\n",
    "   # if i == 0:\n",
    "     #   print(\"No\")\n",
    "   # else:\n",
    "      #  print(\"Yes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
